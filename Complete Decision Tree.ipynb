{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf6240c",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Supervised Classification and Regression algorithm\n",
    "\n",
    "Non-parametric algorithm\n",
    "\n",
    "Most interpretable algorithm.\n",
    "\n",
    "Uses a tree structure to make decisions. Every node represents a decision through which samples can be divided into different branches and leaves represents the classes in the case classification or a numerical value in case of regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e03fa",
   "metadata": {},
   "source": [
    "# Mapping Function\n",
    "No mapping function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a404e61",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Stratifying or segmenting the predictor space into a number of simple regions (leaves or terminal nodes). Uses recursive binary splitting that is the top down greedy approach to successively split the predictor space into branches until a stopping criterion is meet.\n",
    "\n",
    "In case of regression, the leaves are the mean value of the observations falling in that region. In case of classification, the leaves are the classes to which the observations belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea8489",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "For regression, Residual Square of Sum\n",
    "\n",
    "For classification, gini impurity and entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6baac",
   "metadata": {},
   "source": [
    "# gini impurity = Summation [ P_mk ( 1- P_mk ) ] from k = i to C classes\n",
    "P_mk = proportion of training observations in the mth region (leaf) that are from the kth class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee67cb6",
   "metadata": {},
   "source": [
    "# Entropy = - Summation [ P_mk log P_mk ] from k=i to C classes\n",
    "Process of reducing the entropy is known as Information Gain. Lower the entropy, higher the information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362b084",
   "metadata": {},
   "source": [
    "# Shortcomings\n",
    "Very likely to overfit the data beacuse of the complex tree structure hence high variance.\n",
    "\n",
    "It is very non robust. A a small change in the data can cause a large change in the final estimated tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47e511",
   "metadata": {},
   "source": [
    "# Improvement\n",
    "\n",
    "* Cost complexity pruning - This technique helps in reducing overfitting as it prunes the optimal subtree out of the large complex tree. It adds a penality term (similar to the lasso term) in the cost function or the loss function.\n",
    "\n",
    "\n",
    "* Penality term = alpha * |T| where alpha is the tuning parameter and |T| is the number of leaves of the tree as αlpha increases, there is a price to pay for having a tree with many terminal nodes that is the branches get pruned from the tree in a nested and predictable fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916ec88",
   "metadata": {},
   "source": [
    "# BAGGING\n",
    "\n",
    "Bagging technique that is Bootstrap Aggregation where we build separate decision trees using bootstrapped set of samples and average the resulting predictions. Each individual decision tree are grown deep without any pruning and hence each of them has high variance and low bias but averaging them reduces the overall variance. They result in improved accuracy over prediction with a single tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296f1d5",
   "metadata": {},
   "source": [
    "# Disadvantage of bagging\n",
    "\n",
    "Bagging technique suffers from a disadvantage that of any of the predictor is very very strong than the other predictors. Each bagged tree will look similar because most of them will use that strong predictor. Hence the predictions from the bagged trees will be highly correlated. Unfortunately, averaging many highly correlated quantities does not lead to as large of a reduction in variance as averaging many uncorrelated quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0a84e",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Random Forest overcome this problem by forcing each split to consider only a subset of the predictors that are random. The main difference between bagging and random forests is the choice of predictor subset size. If a random forest is built using all the predictors, then it is equal to bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71a3a7",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Boosting works in a similar way, except that the trees are grown sequentially: each tree is grown using information from previously grown trees. Boosting does not involve bootstrap sampling; instead each tree is fit on a modified version of the original data set. Unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown. Because the growth of a particular tree takes into account the other trees that have already been grown, smaller trees are typically sufficient. These smal trees are mostly Stump which have single split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f65ada",
   "metadata": {},
   "source": [
    "# The terms involved in Decision Tree algorithm are as follows:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d62df4",
   "metadata": {},
   "source": [
    "# Root Node\n",
    "It represents the entire population or sample. This further gets divided into two or more homogeneous sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afee834",
   "metadata": {},
   "source": [
    "# Splitting\n",
    "It is a process of dividing a node into two or more sub-nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05af9ed",
   "metadata": {},
   "source": [
    "# Decision Node\n",
    "When a sub-node splits into further sub-nodes, then it is called a decision node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79d9f8",
   "metadata": {},
   "source": [
    "# Leaf/Terminal Node\n",
    "Nodes that do not split are called Leaf or Terminal nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400afe1d",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "When we remove sub-nodes of a decision node, this process is called pruning. It is the opposite process of splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb09b3d",
   "metadata": {},
   "source": [
    "# Branch/Sub-Tree\n",
    "A sub-section of an entire tree is called a branch or sub-tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c2f8e",
   "metadata": {},
   "source": [
    "# Parent and Child Node\n",
    "A node, which is divided into sub-nodes is called the parent node of sub-nodes where sub-nodes are the children of a parent node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90c413",
   "metadata": {},
   "source": [
    "# Decision Tree algorithm intuition\n",
    "\n",
    "* Table of Contents\n",
    "\n",
    "The Decision-Tree algorithm is one of the most frequently and widely used supervised machine learning algorithms that can be used for both classification and regression tasks. The intuition behind the Decision-Tree algorithm is very simple to understand.\n",
    "\n",
    "The Decision Tree algorithm intuition is as follows:-\n",
    "\n",
    " 1) For each attribute in the dataset, the Decision-Tree algorithm forms a node. The most important attribute is placed at the root node.\n",
    "\n",
    "2) For evaluating the task in hand, we start at the root node and we work our way down the tree by following the corresponding node that meets our condition or decision.\n",
    "\n",
    "3) This process continues until a leaf node is reached. It contains the prediction or the outcome of the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cab544",
   "metadata": {},
   "source": [
    "# Attribute selection measures \n",
    "\n",
    "Table of Contents\n",
    "\n",
    "The primary challenge in the Decision Tree implementation is to identify the attributes which we consider as the root node and each level. This process is known as the attributes selection. There are different attributes selection measure to identify the attribute which can be considered as the root node at each level.\n",
    "\n",
    "There are 2 popular attribute selection measures. They are as follows:-\n",
    "\n",
    "* Information gain\n",
    "\n",
    "* Gini index\n",
    "\n",
    "While using Information gain as a criterion, we assume attributes to be categorical and for Gini index attributes are assumed to be continuous. These attribute selection measures are described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b95627",
   "metadata": {},
   "source": [
    "# Information gain \n",
    "\n",
    "Table of Contents\n",
    "\n",
    "By using information gain as a criterion, we try to estimate the information contained by each attribute. To understand the concept of Information Gain, we need to know another concept called Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52593d4e",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "\n",
    "Entropy measures the impurity in the given dataset. In Physics and Mathematics, entropy is referred to as the randomness or uncertainty of a random variable X. In information theory, it refers to the impurity in a group of examples. Information gain is the decrease in entropy. Information gain computes the difference between entropy before split and average entropy after split of the dataset based on given attribute values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9717da",
   "metadata": {},
   "source": [
    "# Here, c is the number of classes and pi is the probability associated with the ith class.\n",
    "\n",
    "The ID3 (Iterative Dichotomiser) Decision Tree algorithm uses entropy to calculate information gain. So, by calculating decrease in entropy measure of each attribute we can calculate their information gain. The attribute with the highest information gain is chosen as the splitting attribute at the node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfee1c",
   "metadata": {},
   "source": [
    "# Gini index \n",
    "Table of Contents\n",
    "\n",
    "Another attribute selection measure that CART (Categorical and Regression Trees) uses is the Gini index. It uses the Gini method to create split points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf54c41",
   "metadata": {},
   "source": [
    "# Gini index says, if we randomly select two items from a population, they must be of the same class and probability for this is 1 if the population is pure.\n",
    "\n",
    "It works with the categorical target variable “Success” or “Failure”. It performs only binary splits. The higher the value of Gini, higher the homogeneity. CART (Classification and Regression Tree) uses the Gini method to create binary splits.\n",
    "\n",
    "Steps to Calculate Gini for a split\n",
    "\n",
    "* Calculate Gini for sub-nodes, using formula sum of the square of probability for success and failure (p^2+q^2).\n",
    "\n",
    "* Calculate Gini for split using weighted Gini score of each node of that split.\n",
    "\n",
    "In case of a discrete-valued attribute, the subset that gives the minimum gini index for that chosen is selected as a splitting attribute. In the case of continuous-valued attributes, the strategy is to select each pair of adjacent values as a possible split-point and point with smaller gini index chosen as the splitting point. The attribute with minimum Gini index is chosen as the splitting attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999dbf48",
   "metadata": {},
   "source": [
    "# Overfitting in Decision Tree algorithm \n",
    "\n",
    "Table of Contents\n",
    "\n",
    "Overfitting is a practical problem while building a Decision-Tree model. The problem of overfitting is considered when the algorithm continues to go deeper and deeper to reduce the training-set error but results with an increased test-set error. So, accuracy of prediction for our model goes down. It generally happens when we build many branches due to outliers and irregularities in data.\n",
    "\n",
    "Two approaches which can be used to avoid overfitting are as follows:-\n",
    "\n",
    "* Pre-Pruning\n",
    "\n",
    "* Post-Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26dc96",
   "metadata": {},
   "source": [
    "# Pre-Pruning\n",
    "\n",
    "In pre-pruning, we stop the tree construction a bit early. We prefer not to split a node if its goodness measure is below a threshold value. But it is difficult to choose an appropriate stopping point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667f81f",
   "metadata": {},
   "source": [
    "# Post-Pruning \n",
    "\n",
    "In post-pruning, we go deeper and deeper in the tree to build a complete tree. If the tree shows the overfitting problem then pruning is done as a post-pruning step. We use the cross-validation data to check the effect of our pruning. Using cross-validation data, we test whether expanding a node will result in improve or not. If it shows an improvement, then we can continue by expanding that node. But if it shows a reduction in accuracy then it should not be expanded. So, the node should be converted to a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7099ad5",
   "metadata": {},
   "source": [
    "# 1 importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db39e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96da7bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"C:/Users/HOME/Desktop/dataset/kaggle_dataset/car_evaluation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759b8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97666a61",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6882854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported AutoViz_Class version: 0.0.84. Call using:\n",
      "    AV = AutoViz_Class()\n",
      "    AV.AutoViz(filename, sep=',', depVar='', dfte=None, header=0, verbose=0,\n",
      "                            lowess=False,chart_format='svg',max_rows_analyzed=150000,max_cols_analyzed=30)\n",
      "Note: verbose=0 or 1 generates charts and displays them in your local Jupyter notebook.\n",
      "      verbose=2 does not show plot but creates them and saves them in AutoViz_Plots directory in your local machine.\n",
      "Shape of your Data Set loaded: (1727, 7)\n",
      "############## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "Classifying variables in data set...\n",
      "    Number of Numeric Columns =  0\n",
      "    Number of Integer-Categorical Columns =  0\n",
      "    Number of String-Categorical Columns =  7\n",
      "    Number of Factor-Categorical Columns =  0\n",
      "    Number of String-Boolean Columns =  0\n",
      "    Number of Numeric-Boolean Columns =  0\n",
      "    Number of Discrete String Columns =  0\n",
      "    Number of NLP String Columns =  0\n",
      "    Number of Date Time Columns =  0\n",
      "    Number of ID Columns =  0\n",
      "    Number of Columns to Delete =  0\n",
      "    7 Predictors classified...\n",
      "        This does not include the Target column(s)\n",
      "        No variables removed since no ID or low-information variables found in data set\n",
      "No continuous variables in this data set. No visualization can be performed\n",
      "Not able to read or load file. Please check your inputs and try again...\n"
     ]
    }
   ],
   "source": [
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "AV = AutoViz_Class()\n",
    "df_1 = AV.AutoViz(\"C:/Users/HOME/Desktop/dataset/kaggle_dataset/car_evaluation.csv\")\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef9ae09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ee5cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4b0638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878f1c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      " 6   class     1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#View summary of dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27d10f",
   "metadata": {},
   "source": [
    "# Frequency distribution of values in variables\n",
    "Now, I will check the frequency counts of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790b215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vhigh    432\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "Name: buying, dtype: int64\n",
      "vhigh    432\n",
      "high     432\n",
      "med      432\n",
      "low      432\n",
      "Name: maint, dtype: int64\n",
      "2        432\n",
      "3        432\n",
      "4        432\n",
      "5more    432\n",
      "Name: doors, dtype: int64\n",
      "2       576\n",
      "4       576\n",
      "more    576\n",
      "Name: persons, dtype: int64\n",
      "small    576\n",
      "med      576\n",
      "big      576\n",
      "Name: lug_boot, dtype: int64\n",
      "low     576\n",
      "med     576\n",
      "high    576\n",
      "Name: safety, dtype: int64\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "\n",
    "for col in col_names:\n",
    "    \n",
    "    print(df[col].value_counts())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd8455",
   "metadata": {},
   "source": [
    "# Summary of variables\n",
    "There are 7 variables in the dataset. All the variables are of categorical data type.\n",
    "These are given by buying, maint, doors, persons, lug_boot, safety and class.\n",
    "class is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4519be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b4af7",
   "metadata": {},
   "source": [
    "The class target variable is ordinal in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24893cd6",
   "metadata": {},
   "source": [
    "# Missing values in variables¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b600cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in variables\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e4cbb",
   "metadata": {},
   "source": [
    "# Declare feature vector and target variable ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e195e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'], axis=1)\n",
    "\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0cd43",
   "metadata": {},
   "source": [
    "# Split data into separate training and test set ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc6bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad07e385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1157, 6), (571, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ded2c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575e7a8",
   "metadata": {},
   "source": [
    "Feature Engineering is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61deaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      object\n",
       "maint       object\n",
       "doors       object\n",
       "persons     object\n",
       "lug_boot    object\n",
       "safety      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de1057",
   "metadata": {},
   "source": [
    "# Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae721057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety\n",
       "48    vhigh  vhigh      3    more      med    low\n",
       "468    high  vhigh      3       4    small    low\n",
       "155   vhigh   high      3    more    small   high\n",
       "1721    low    low  5more    more    small   high\n",
       "1208    med    low      2    more    small   high"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de925c",
   "metadata": {},
   "source": [
    "see that all the variables are ordinal categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff9e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category encoders\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a09b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode variables with ordinal encoding\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ae6df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "48         1      1      1        1         1       1\n",
       "468        2      1      1        2         2       1\n",
       "155        1      2      1        1         2       2\n",
       "1721       3      3      2        1         2       2\n",
       "1208       4      3      3        1         2       2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b605476f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "599        2      2      4        3         1       2\n",
       "1201       4      3      3        2         1       3\n",
       "628        2      2      2        3         3       3\n",
       "1498       3      2      2        2         1       3\n",
       "1263       4      3      4        1         1       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c23455",
   "metadata": {},
   "source": [
    "We now have training and test set ready for model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33afea",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier with criterion gini index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264df66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ce57e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n",
    "\n",
    "\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c669c",
   "metadata": {},
   "source": [
    "# Predict the Test set results with criterion gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "219c0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gini = clf_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640930c7",
   "metadata": {},
   "source": [
    "# Check accuracy score with criterion gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43a0b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with criterion gini index: 0.8021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf72411",
   "metadata": {},
   "source": [
    " Here, y_test are the true class labels and y_pred_gini are the predicted class labels in the test-set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8afae",
   "metadata": {},
   "source": [
    "# Compare the train-set and test-set accuracy\n",
    "Now, I will compare the train-set and test-set accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce010df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'unacc', 'unacc', ..., 'unacc', 'unacc', 'acc'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_gini = clf_gini.predict(X_train)\n",
    "\n",
    "y_pred_train_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7b75d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.7865\n"
     ]
    }
   ],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e541b",
   "metadata": {},
   "source": [
    "# Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "391e221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.7865\n",
      "Test set score: 0.8021\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01f907",
   "metadata": {},
   "source": [
    "Here, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca48f0",
   "metadata": {},
   "source": [
    "# Visualize decision-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c84ea2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(267.84000000000003, 380.52, 'X[5] <= 1.5\\ngini = 0.455\\nsamples = 1157\\nvalue = [255, 49, 813, 40]'),\n",
       " Text(133.92000000000002, 271.8, 'gini = 0.0\\nsamples = 386\\nvalue = [0, 0, 386, 0]'),\n",
       " Text(401.76000000000005, 271.8, 'X[3] <= 2.5\\ngini = 0.577\\nsamples = 771\\nvalue = [255, 49, 427, 40]'),\n",
       " Text(267.84000000000003, 163.07999999999998, 'X[0] <= 2.5\\ngini = 0.631\\nsamples = 525\\nvalue = [255, 49, 181, 40]'),\n",
       " Text(133.92000000000002, 54.360000000000014, 'gini = 0.496\\nsamples = 271\\nvalue = [124, 0, 147, 0]'),\n",
       " Text(401.76000000000005, 54.360000000000014, 'gini = 0.654\\nsamples = 254\\nvalue = [131, 49, 34, 40]'),\n",
       " Text(535.6800000000001, 163.07999999999998, 'gini = 0.0\\nsamples = 246\\nvalue = [0, 0, 246, 0]')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(clf_gini.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985c40c",
   "metadata": {},
   "source": [
    "# Visualize decision-trees with graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1513280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"433pt\" height=\"433pt\"\r\n",
       " viewBox=\"0.00 0.00 433.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-429 429,-429 429,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#85c2ef\" stroke=\"black\" d=\"M249.5,-425C249.5,-425 95.5,-425 95.5,-425 89.5,-425 83.5,-419 83.5,-413 83.5,-413 83.5,-354 83.5,-354 83.5,-348 89.5,-342 95.5,-342 95.5,-342 249.5,-342 249.5,-342 255.5,-342 261.5,-348 261.5,-354 261.5,-354 261.5,-413 261.5,-413 261.5,-419 255.5,-425 249.5,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"135.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">safety ≤ 1.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"135\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.455</text>\r\n",
       "<text text-anchor=\"start\" x=\"121\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1157</text>\r\n",
       "<text text-anchor=\"start\" x=\"91.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [255, 49, 813, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M143,-298.5C143,-298.5 22,-298.5 22,-298.5 16,-298.5 10,-292.5 10,-286.5 10,-286.5 10,-242.5 10,-242.5 10,-236.5 16,-230.5 22,-230.5 22,-230.5 143,-230.5 143,-230.5 149,-230.5 155,-236.5 155,-242.5 155,-242.5 155,-286.5 155,-286.5 155,-292.5 149,-298.5 143,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"53.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"35\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 386</text>\r\n",
       "<text text-anchor=\"start\" x=\"18\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 386, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"39\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.275,-341.907C132.532,-330.542 123.022,-318.178 114.249,-306.774\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.884,-304.459 108.013,-298.667 111.336,-308.727 116.884,-304.459\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"104.78\" y=\"-319.757\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#bddef6\" stroke=\"black\" d=\"M339.5,-306C339.5,-306 185.5,-306 185.5,-306 179.5,-306 173.5,-300 173.5,-294 173.5,-294 173.5,-235 173.5,-235 173.5,-229 179.5,-223 185.5,-223 185.5,-223 339.5,-223 339.5,-223 345.5,-223 351.5,-229 351.5,-235 351.5,-235 351.5,-294 351.5,-294 351.5,-300 345.5,-306 339.5,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"218.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">persons ≤ 2.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"225\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.577</text>\r\n",
       "<text text-anchor=\"start\" x=\"215\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 771</text>\r\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [255, 49, 427, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"219\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.725,-341.907C210.636,-332.923 218.027,-323.315 225.154,-314.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.007,-316.081 231.33,-306.021 222.459,-311.813 228.007,-316.081\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"234.564\" y=\"-327.111\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#f9e4d4\" stroke=\"black\" d=\"M249.5,-187C249.5,-187 95.5,-187 95.5,-187 89.5,-187 83.5,-181 83.5,-175 83.5,-175 83.5,-116 83.5,-116 83.5,-110 89.5,-104 95.5,-104 95.5,-104 249.5,-104 249.5,-104 255.5,-104 261.5,-110 261.5,-116 261.5,-116 261.5,-175 261.5,-175 261.5,-181 255.5,-187 249.5,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">buying ≤ 2.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"135\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.631</text>\r\n",
       "<text text-anchor=\"start\" x=\"125\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 525</text>\r\n",
       "<text text-anchor=\"start\" x=\"91.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [255, 49, 181, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.275,-222.907C224.364,-213.923 216.973,-204.315 209.846,-195.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.541,-192.813 203.67,-187.021 206.993,-197.081 212.541,-192.813\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M413,-179.5C413,-179.5 292,-179.5 292,-179.5 286,-179.5 280,-173.5 280,-167.5 280,-167.5 280,-123.5 280,-123.5 280,-117.5 286,-111.5 292,-111.5 292,-111.5 413,-111.5 413,-111.5 419,-111.5 425,-117.5 425,-123.5 425,-123.5 425,-167.5 425,-167.5 425,-173.5 419,-179.5 413,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"323.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"305\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 246</text>\r\n",
       "<text text-anchor=\"start\" x=\"288\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 246, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"309\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M293.725,-222.907C302.468,-211.542 311.978,-199.178 320.751,-187.774\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.664,-189.727 326.987,-179.667 318.116,-185.459 323.664,-189.727\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#e0f0fb\" stroke=\"black\" d=\"M149,-68C149,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 149,-0 149,-0 155,-0 161,-6 161,-12 161,-12 161,-56 161,-56 161,-62 155,-68 149,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"43\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.496</text>\r\n",
       "<text text-anchor=\"start\" x=\"33\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 271</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [124, 0, 147, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"37\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.243,-103.726C130.656,-94.6966 122.613,-85.1235 115.016,-76.0816\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.59,-73.7045 108.478,-68.2996 112.231,-78.2075 117.59,-73.7045\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#f5cdb0\" stroke=\"black\" d=\"M337.5,-68C337.5,-68 191.5,-68 191.5,-68 185.5,-68 179.5,-62 179.5,-56 179.5,-56 179.5,-12 179.5,-12 179.5,-6 185.5,-0 191.5,-0 191.5,-0 337.5,-0 337.5,-0 343.5,-0 349.5,-6 349.5,-12 349.5,-12 349.5,-56 349.5,-56 349.5,-62 343.5,-68 337.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"227\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.654</text>\r\n",
       "<text text-anchor=\"start\" x=\"217\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 254</text>\r\n",
       "<text text-anchor=\"start\" x=\"187.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [131, 49, 34, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"221\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M206.757,-103.726C214.344,-94.6966 222.387,-85.1235 229.984,-76.0816\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.769,-78.2075 236.522,-68.2996 227.41,-73.7045 232.769,-78.2075\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x299267a6b20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf_gini, out_file=None, \n",
    "                              feature_names=X_train.columns,  \n",
    "                              class_names=y_train,  \n",
    "                              filled=True, rounded=True,  \n",
    "                              special_characters=True)\n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1da7f",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier with criterion entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1da6af76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "\n",
    "\n",
    "clf_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4f96",
   "metadata": {},
   "source": [
    "Predict the Test set results with criterion entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e5688f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_en = clf_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb59c0",
   "metadata": {},
   "source": [
    "# Check accuracy score with criterion entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80dee395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with criterion entropy: 0.8021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Model accuracy score with criterion entropy: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73ed32",
   "metadata": {},
   "source": [
    "# Compare the train-set and test-set accuracy\n",
    "Now, I will compare the train-set and test-set accuracy to check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ca33b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'unacc', 'unacc', ..., 'unacc', 'unacc', 'acc'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_en = clf_en.predict(X_train)\n",
    "\n",
    "y_pred_train_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b0101a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.7865\n"
     ]
    }
   ],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_en)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8749745",
   "metadata": {},
   "source": [
    "# Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4e29604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.7865\n",
      "Test set score: 0.8021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6e742",
   "metadata": {},
   "source": [
    "We can see that the training-set score and test-set score is same as above. The training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef15f33",
   "metadata": {},
   "source": [
    "# Visualize decision-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25e87dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(267.84000000000003, 380.52, 'X[5] <= 1.5\\nentropy = 1.2\\nsamples = 1157\\nvalue = [255, 49, 813, 40]'),\n",
       " Text(133.92000000000002, 271.8, 'entropy = 0.0\\nsamples = 386\\nvalue = [0, 0, 386, 0]'),\n",
       " Text(401.76000000000005, 271.8, 'X[3] <= 2.5\\nentropy = 1.474\\nsamples = 771\\nvalue = [255, 49, 427, 40]'),\n",
       " Text(267.84000000000003, 163.07999999999998, 'X[0] <= 2.5\\nentropy = 1.638\\nsamples = 525\\nvalue = [255, 49, 181, 40]'),\n",
       " Text(133.92000000000002, 54.360000000000014, 'entropy = 0.995\\nsamples = 271\\nvalue = [124, 0, 147, 0]'),\n",
       " Text(401.76000000000005, 54.360000000000014, 'entropy = 1.759\\nsamples = 254\\nvalue = [131, 49, 34, 40]'),\n",
       " Text(535.6800000000001, 163.07999999999998, 'entropy = 0.0\\nsamples = 246\\nvalue = [0, 0, 246, 0]')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(clf_en.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbad89fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"433pt\" height=\"433pt\"\r\n",
       " viewBox=\"0.00 0.00 433.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-429 429,-429 429,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#85c2ef\" stroke=\"black\" d=\"M249.5,-425C249.5,-425 95.5,-425 95.5,-425 89.5,-425 83.5,-419 83.5,-413 83.5,-413 83.5,-354 83.5,-354 83.5,-348 89.5,-342 95.5,-342 95.5,-342 249.5,-342 249.5,-342 255.5,-342 261.5,-348 261.5,-354 261.5,-354 261.5,-413 261.5,-413 261.5,-419 255.5,-425 249.5,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"135.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">safety ≤ 1.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"130.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.2</text>\r\n",
       "<text text-anchor=\"start\" x=\"121\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1157</text>\r\n",
       "<text text-anchor=\"start\" x=\"91.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [255, 49, 813, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M143,-298.5C143,-298.5 22,-298.5 22,-298.5 16,-298.5 10,-292.5 10,-286.5 10,-286.5 10,-242.5 10,-242.5 10,-236.5 16,-230.5 22,-230.5 22,-230.5 143,-230.5 143,-230.5 149,-230.5 155,-236.5 155,-242.5 155,-242.5 155,-286.5 155,-286.5 155,-292.5 149,-298.5 143,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"40.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"35\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 386</text>\r\n",
       "<text text-anchor=\"start\" x=\"18\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 386, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"39\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.275,-341.907C132.532,-330.542 123.022,-318.178 114.249,-306.774\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.884,-304.459 108.013,-298.667 111.336,-308.727 116.884,-304.459\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"104.78\" y=\"-319.757\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#bddef6\" stroke=\"black\" d=\"M339.5,-306C339.5,-306 185.5,-306 185.5,-306 179.5,-306 173.5,-300 173.5,-294 173.5,-294 173.5,-235 173.5,-235 173.5,-229 179.5,-223 185.5,-223 185.5,-223 339.5,-223 339.5,-223 345.5,-223 351.5,-229 351.5,-235 351.5,-235 351.5,-294 351.5,-294 351.5,-300 345.5,-306 339.5,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"218.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">persons ≤ 2.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"212.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.474</text>\r\n",
       "<text text-anchor=\"start\" x=\"215\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 771</text>\r\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [255, 49, 427, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"219\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.725,-341.907C210.636,-332.923 218.027,-323.315 225.154,-314.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.007,-316.081 231.33,-306.021 222.459,-311.813 228.007,-316.081\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"234.564\" y=\"-327.111\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#f9e4d4\" stroke=\"black\" d=\"M249.5,-187C249.5,-187 95.5,-187 95.5,-187 89.5,-187 83.5,-181 83.5,-175 83.5,-175 83.5,-116 83.5,-116 83.5,-110 89.5,-104 95.5,-104 95.5,-104 249.5,-104 249.5,-104 255.5,-104 261.5,-110 261.5,-116 261.5,-116 261.5,-175 261.5,-175 261.5,-181 255.5,-187 249.5,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">buying ≤ 2.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"122.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.638</text>\r\n",
       "<text text-anchor=\"start\" x=\"125\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 525</text>\r\n",
       "<text text-anchor=\"start\" x=\"91.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [255, 49, 181, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.275,-222.907C224.364,-213.923 216.973,-204.315 209.846,-195.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.541,-192.813 203.67,-187.021 206.993,-197.081 212.541,-192.813\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M413,-179.5C413,-179.5 292,-179.5 292,-179.5 286,-179.5 280,-173.5 280,-167.5 280,-167.5 280,-123.5 280,-123.5 280,-117.5 286,-111.5 292,-111.5 292,-111.5 413,-111.5 413,-111.5 419,-111.5 425,-117.5 425,-123.5 425,-123.5 425,-167.5 425,-167.5 425,-173.5 419,-179.5 413,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"310.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"305\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 246</text>\r\n",
       "<text text-anchor=\"start\" x=\"288\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 246, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"309\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M293.725,-222.907C302.468,-211.542 311.978,-199.178 320.751,-187.774\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.664,-189.727 326.987,-179.667 318.116,-185.459 323.664,-189.727\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#e0f0fb\" stroke=\"black\" d=\"M149,-68C149,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 149,-0 149,-0 155,-0 161,-6 161,-12 161,-12 161,-56 161,-56 161,-62 155,-68 149,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"30.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.995</text>\r\n",
       "<text text-anchor=\"start\" x=\"33\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 271</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [124, 0, 147, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"37\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.243,-103.726C130.656,-94.6966 122.613,-85.1235 115.016,-76.0816\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.59,-73.7045 108.478,-68.2996 112.231,-78.2075 117.59,-73.7045\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#f5cdb0\" stroke=\"black\" d=\"M337.5,-68C337.5,-68 191.5,-68 191.5,-68 185.5,-68 179.5,-62 179.5,-56 179.5,-56 179.5,-12 179.5,-12 179.5,-6 185.5,-0 191.5,-0 191.5,-0 337.5,-0 337.5,-0 343.5,-0 349.5,-6 349.5,-12 349.5,-12 349.5,-56 349.5,-56 349.5,-62 343.5,-68 337.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"214.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.759</text>\r\n",
       "<text text-anchor=\"start\" x=\"217\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 254</text>\r\n",
       "<text text-anchor=\"start\" x=\"187.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [131, 49, 34, 40]</text>\r\n",
       "<text text-anchor=\"start\" x=\"221\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = unacc</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M206.757,-103.726C214.344,-94.6966 222.387,-85.1235 229.984,-76.0816\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.769,-78.2075 236.522,-68.2996 227.41,-73.7045 232.769,-78.2075\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x299267ef340>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf_en, out_file=None, \n",
    "                              feature_names=X_train.columns,  \n",
    "                              class_names=y_train,  \n",
    "                              filled=True, rounded=True,  \n",
    "                              special_characters=True)\n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131d533",
   "metadata": {},
   "source": [
    "Now, based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n",
    "\n",
    "But, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making.\n",
    "\n",
    "We have another tool called Confusion matrix that comes to our rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e647c5",
   "metadata": {},
   "source": [
    "# Confusion matrix \n",
    "\n",
    "Table of Contents\n",
    "\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "True Positives (TP) – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "True Negatives (TN) – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "False Positives (FP) – False Positives occur when we predict an observation belongs to a certain class but the observation actually does not belong to that class. This type of error is called Type I error.\n",
    "\n",
    "False Negatives (FN) – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called Type II error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13d438ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[ 73   0  56   0]\n",
      " [ 20   0   0   0]\n",
      " [ 12   0 385   0]\n",
      " [ 25   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_en)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bd35a",
   "metadata": {},
   "source": [
    "# Classification Report \n",
    "Table of Contents\n",
    "\n",
    "Classification report is another way to evaluate the classification model performance. It displays the precision, recall, f1 and support scores for the model. I have described these terms in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "107fbdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.56      0.57      0.56       129\n",
      "        good       0.00      0.00      0.00        20\n",
      "       unacc       0.87      0.97      0.92       397\n",
      "       vgood       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.36      0.38      0.37       571\n",
      "weighted avg       0.73      0.80      0.77       571\n",
      "\n",
      "Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 23:59:27,327 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 23:59:31,407 - INFO     - Executing shutdown...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb79421",
   "metadata": {},
   "source": [
    "# Results and conclusion \n",
    "\n",
    "Table of Contents\n",
    "\n",
    "* In this project, I build a Decision-Tree Classifier model to predict the safety of the car. I build two models, one with criterion gini index and another one with criterion entropy. The model yields a very good performance as indicated by the model accuracy in both the cases which was found to be 0.8021.\n",
    "\n",
    "* In the model with criterion gini index, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting.\n",
    "\n",
    "* Similarly, in the model with criterion entropy, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021.We get the same values as in the case with criterion gini. So, there is no sign of overfitting.\n",
    "\n",
    "* In both the cases, the training-set and test-set accuracy score is the same. It may happen because of small dataset.\n",
    "\n",
    "* The confusion matrix and classification report yields very good model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2f4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
